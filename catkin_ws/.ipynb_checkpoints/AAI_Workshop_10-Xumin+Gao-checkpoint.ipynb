{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMP9767M - Automatic detection and counting of grape bunches by robots\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://github.com/TheMemoryDealer/Robot-Programming-CMP9767M/blob/main/weeder/assets/FINAL.gif\" width=\"1500\" alt=\"animated\" />\n",
    "</p>\n",
    "\n",
    "\n",
    "## Solution\n",
    "My focus area is **Perception**. In this task, the robot can **accurately count all grape bunches in the vineyard and obtain the 3D spatial coordinates of all grape bunches**. Firstly, the robot uses **yolov3** to detect grape bunches, which can effectively solve the detection of multiple targets with partially overlapping regions in the image. Then calculating euclidean distance to **track** center of targets from different camera frames when robot is moving. After that, according to the target's center coordinates on color image and the corresponding depth distance on depth image, calculating target's **3D position** in world coordinate frame by using TF tree in ROS. Meanwhile, using **spatial qualified method** to filter out target's location noises. Finally, the robot can complete the counting task and publish the 3D poses of all grape bunches to the rviz interface. For the navigation, the robot realizes **autonomous navigation** around the grape trellis using the pre-established topology map and movebase package in ROS. **The github page** can be found https://github.com/leggedrobotics/darknet_ros.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "**1.** Ensure your system is Ubuntu18.04 with Python2. Meanwhile, installs L-CAS Ubuntu/ROS software distribution:  https://github.com/LCAS/CMP9767M/wiki/useful-resources#install-the-l-cas-ubuntu-distribution-for-the-module-on-your-own-pc  \n",
    "\n",
    "**2.** This work is based on https://github.com/LCAS/CMP9767M. Clone it into your catkin_ws workspace.  \n",
    "\n",
    "**3.** Ensure your system has installed cuda_10.1/cuda_11.5 and cudnn_7.6.5 which can run Yolov3. If you use other versoins of cuda and cudnn, please follow the instruction https://github.com/leggedrobotics/darknet_ros to compile the darknet_ros package.\n",
    "\n",
    "**4.** Ensure your system has installed opencv_4.1.0 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation and Run\n",
    "**1. Clone repo and recompile**   \n",
    "Clone my repository into your workspace and recompile it:  \n",
    "`cd catkin_ws/`  \n",
    "`catkin_make`  \n",
    "`~/catkin_ws/devel/setup.bash`  \n",
    "\n",
    "Meanwhile, please follow the instruction https://github.com/leggedrobotics/darknet_ros , if you encounter some compilation problems in the part of darknet_ros. Before you recompile, please empty ./catkin_ws/build folder.\n",
    "\n",
    "**2. Introduction of main file directories**  \n",
    "\n",
    "**./catkin_ws/src/CMP9767M-master**    \n",
    "This is a basic package for establishing the environment of this project. From https://github.com/LCAS/CMP9767M\n",
    "\n",
    "**./catkin_ws/src/darknet_ros**    \n",
    "This is a Ros package for darknet, where robot will use Yolov3 to implement the detection of grape bunches and publish detection information including bounding_boxes, classes, detection probability. From https://github.com/leggedrobotics/darknet_ros\n",
    "\n",
    "**./catkin_ws/src/grape_bunches_count**    \n",
    "This is the core function implementation package of this project, I will introduce several main Python files below:   \n",
    "* ./catkin_ws/src/grape_bunches_count/src/detection_count.py  \n",
    "   *This Python file is the core program to realize detection, tracking, 3D location and counting of grape bunches, and make robot realize autonomous navigation.*  \n",
    "\n",
    "\n",
    "* ./catkin_ws/src/grape_bunches_count/src/simple_depth_register_node.py  \n",
    "   *This Python file is the node which is used to register color image and depth image, so as to obtain the depth distance of target's center.*\n",
    "   \n",
    "\n",
    "* ./catkin_ws/src/grape_bunches_count/src/navigation.py  \n",
    "   *This Python file is topology_navigation node.*\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Install packages**  \n",
    "Update: `sudo apt-get update && sudo apt-get upgrade`  \n",
    "then install following packages:  \n",
    "    ```\n",
    "    sudo apt-get install \\\n",
    "        ros-melodic-opencv-apps \\\n",
    "        ros-melodic-rqt-image-view \\\n",
    "        ros-melodic-image-geometry \\\n",
    "        ros-melodic-uol-cmp9767m-base \\\n",
    "        ros-melodic-uol-cmp9767m-tutorial \\\n",
    "        ros-melodic-find-object-2d \\\n",
    "        ros-melodic-video-stream-opencv \\\n",
    "        ros-melodic-topic-tools \\\n",
    "        ros-melodic-rqt-tf-tree \\\n",
    "        ros-melodic-image-view \\\n",
    "        ros-melodic-robot-localization \\\n",
    "        ros-melodic-thorvald \\\n",
    "        ros-melodic-velodyne-description \\\n",
    "        ros-melodic-kinect2-description \\\n",
    "        ros-melodic-topological-navigation \\\n",
    "        ros-melodic-teleop-tools \\\n",
    "        ros-melodic-fake-localization \\\n",
    "        ros-melodic-carrot-planner \\\n",
    "        ros-melodic-amcl \\\n",
    "        ros-melodic-topological-navigation-msgs \\\n",
    "        ros-melodic-topological-utils \\\n",
    "        ros-melodic-strands-navigation \\\n",
    "        ros-melodic-gmapping \\\n",
    "        ros-melodic-robot-pose-publisher\n",
    "    ```\n",
    "    \n",
    "**4. Run**  \n",
    "There are two methods to do it.\n",
    "\n",
    "**1) One way**\n",
    "\n",
    "Creat mongodb file to store the data of topology map and topology navigation:    \n",
    "`cd && mkdir mongodb`  \n",
    "Launch gazebo simulation environment:    \n",
    "`roslaunch bacchus_gazebo vineyard_demo.launch world_name:=vineyard_small`  \n",
    "Launch topology_navigation node:    \n",
    "`roslaunch uol_cmp9767m_tutorial topo_nav.launch`  \n",
    "Load map into mongodb(only once):  \n",
    "`rosrun topological_utils load_yaml_map.py $(rospack find grape_bunches_count)/maps/map.yaml`  \n",
    "Launch topology_navigation rviz:  \n",
    "`rviz -d $(rospack find uol_cmp9767m_tutorial)/config/topo_nav.rviz`  \n",
    "Launch darknet_ros:    \n",
    "`roslaunch darknet_ros yolo_v3.launch`    \n",
    "Run registration node which is used to register color image and depth image:      \n",
    "`rosrun grape_bunches_count simple_depth_register_node.py`    \n",
    "Run count:    \n",
    "`rosrun grape_bunches_count detection_count.py`  \n",
    "Run autonomous navigation:  \n",
    "`rosrun grape_bunches_count navigation.py` \n",
    "\n",
    "**Finally, don't forget to start up your gazebo simulation.**\n",
    "\n",
    "\n",
    "**2) Another way**\n",
    "\n",
    "There is a quick way to run above all of commands,at first:      \n",
    "`roslaunch grape_bunches_count run.launch`  \n",
    "\n",
    " ***Waiting for gazebo simulatation is ready and start up it***, then  \n",
    "`roslaunch grape_bunches_count topo_nav.launch`  \n",
    "\n",
    "The reason why needs to do it by two steps is that topo_nav.rviz must be launched after topo_nav.launch taking effect. Otherwise, the rviz display of the topology map is a little abnormal, although it does not affect the whole execution process.  \n",
    "\n",
    "**5. Tips**:  \n",
    "* Setup.bash to your ~/.bashrc  \n",
    "`sudo gedit ~/.bashrc`   \n",
    "Add the lines to the bottom of the file  \n",
    "`source /home/<USERNAME>/catkin_ws/devel/setup.bash`  \n",
    "Don't forget to source your environment\n",
    "`source ~/.bashrc`    \n",
    "\n",
    "\n",
    "* Before you restart the simulation, run `killall -9 gzserver` on terminal window in order to ensure all simulator instances have been terminated. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contact\n",
    "Xumin Gao (https://github.com/XuminGaoGithub)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
